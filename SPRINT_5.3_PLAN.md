# Sprint 5.3 Plan - Integration Pipeline (Document Structurer + Technical Analyst)

**Data de In√≠cio:** 08 de novembro de 2025
**Dura√ß√£o Estimada:** 10-12 horas
**Objetivo:** Criar pipeline end-to-end integrando Document Structurer com Query Processor

---

## üéØ Objetivo da Hist√≥ria

Implementar a **Hist√≥ria 5.3 - Integration Pipeline**, que:
1. Integra Document Structurer (extra√ß√£o de requisitos) com Query Processor (an√°lise)
2. Cria pipeline completo: PDF ‚Üí Extra√ß√£o ‚Üí An√°lise RAG ‚Üí Relat√≥rio
3. Implementa an√°lise de conformidade batch para todos os requisitos
4. Gera relat√≥rios consolidados com veredictos e evid√™ncias
5. Fornece comando `/analyze-edital` para an√°lise completa

---

## üìã Crit√©rios de Aceita√ß√£o

- [ ] Classe `AnalysisPipeline` implementada
- [ ] Integra√ß√£o Document Structurer ‚Üí Query Processor funcional
- [ ] An√°lise batch de requisitos contra knowledge base
- [ ] Relat√≥rio consolidado com estrutura + an√°lise
- [ ] Exporta√ß√£o em m√∫ltiplos formatos (CSV, JSON, Excel, Markdown)
- [ ] Comando `/analyze-edital` funcional
- [ ] Testes de integra√ß√£o end-to-end
- [ ] Documenta√ß√£o completa do pipeline
- [ ] Performance aceit√°vel (< 5min para edital t√≠pico)

---

## üèóÔ∏è Arquitetura

### Pipeline End-to-End

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  ANALYZE EDITAL                        ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ  1Ô∏è‚É£ Document Structurer                               ‚îÇ
‚îÇ     PDF Input ‚Üí Text Extraction ‚Üí Requirements        ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ OCR (if needed)                               ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ Metadata Extraction                           ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ Structured CSV Output                         ‚îÇ
‚îÇ                    ‚îÇ                                   ‚îÇ
‚îÇ                    ‚ñº                                   ‚îÇ
‚îÇ  2Ô∏è‚É£ Technical Analyst (Query Processor)               ‚îÇ
‚îÇ     Requirements ‚Üí RAG Search ‚Üí Conformity Analysis   ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ Batch Processing                              ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ Evidence Extraction                           ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ Verdict Generation                            ‚îÇ
‚îÇ                    ‚îÇ                                   ‚îÇ
‚îÇ                    ‚ñº                                   ‚îÇ
‚îÇ  3Ô∏è‚É£ Report Generator                                  ‚îÇ
‚îÇ     Analysis Results ‚Üí Consolidated Report            ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ CSV (requirements + verdicts)                 ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ JSON (full analysis)                          ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ Excel (multi-sheet)                           ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ Markdown (human-readable)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes

```python
# New components for Sprint 5.3

AnalysisPipeline
‚îú‚îÄ‚îÄ analyze_edital()           # Main entry point
‚îú‚îÄ‚îÄ _extract_requirements()    # Document Structurer integration
‚îú‚îÄ‚îÄ _analyze_conformity()      # Query Processor integration
‚îú‚îÄ‚îÄ _generate_report()         # Report generation
‚îî‚îÄ‚îÄ _export()                  # Multi-format export

ConformityReport
‚îú‚îÄ‚îÄ summary                    # High-level stats
‚îú‚îÄ‚îÄ requirements               # Structured requirements
‚îú‚îÄ‚îÄ analysis_results           # Conformity analysis per requirement
‚îú‚îÄ‚îÄ evidence                   # All evidence collected
‚îî‚îÄ‚îÄ recommendations            # Consolidated recommendations

ReportExporter
‚îú‚îÄ‚îÄ to_csv()                   # Enhanced CSV with analysis
‚îú‚îÄ‚îÄ to_json()                  # Complete JSON export
‚îú‚îÄ‚îÄ to_excel()                 # Multi-sheet Excel
‚îî‚îÄ‚îÄ to_markdown()              # Human-readable report
```

---

## üìä Estrutura de Dados

### Input (PDF Edital)
```
edital_123.pdf (50 pages, 2MB)
```

### Stage 1 Output (Document Structurer)
```python
{
    "metadata": {
        "numero_edital": "001/2024",
        "orgao": "Prefeitura Municipal",
        "modalidade": "Preg√£o Eletr√¥nico",
        ...
    },
    "requirements": [
        {
            "id": "REQ-001",
            "descricao": "C√¢meras IP com resolu√ß√£o m√≠nima 4MP",
            "tipo": "T√©cnico",
            "categoria": "Hardware",
            "prioridade": "Alta",
            "fonte": "Item 3.1.2",
            "pagina": 12
        },
        # ... 50 requirements
    ]
}
```

### Stage 2 Output (Query Processor)
```python
{
    "requirement_id": "REQ-001",
    "conformity": "CONFORME",
    "confidence": 0.92,
    "evidence": [
        {
            "source": "requisitos_tecnicos.md",
            "text": "C√¢meras IP devem ter resolu√ß√£o m√≠nima de 4MP...",
            "relevance": 0.94
        }
    ],
    "reasoning": "O requisito est√° em conformidade...",
    "recommendations": ["‚úÖ Requisito validado"]
}
```

### Final Output (Consolidated Report)
```python
{
    "edital_info": {...},
    "summary": {
        "total_requirements": 50,
        "conforme": 35,
        "nao_conforme": 2,
        "revisao": 13,
        "overall_compliance": "70%"
    },
    "detailed_analysis": [
        {
            "requirement": {...},
            "analysis": {...},
            "verdict": "CONFORME",
            "confidence": 0.92
        }
    ],
    "recommendations": [
        "13 requisitos necessitam revis√£o manual",
        "2 requisitos identificados como n√£o conformes"
    ]
}
```

---

## üîß Implementa√ß√£o

### 1. AnalysisPipeline (agents/technical_analyst/pipeline.py)

```python
from typing import Dict, List, Any, Optional
from pathlib import Path
import json
from datetime import datetime

from agents.document_structurer.document_structurer import DocumentStructurer
from agents.technical_analyst import QueryProcessor, RAGEngine
from agents.technical_analyst.report import ConformityReport, ReportExporter


class AnalysisPipeline:
    """
    End-to-end pipeline for edital analysis

    Integrates Document Structurer and Technical Analyst to provide
    complete analysis from PDF to conformity report.
    """

    def __init__(
        self,
        rag_engine: Optional[RAGEngine] = None,
        output_dir: str = "output/analysis"
    ):
        """
        Initialize analysis pipeline

        Args:
            rag_engine: RAG engine (will create default if not provided)
            output_dir: Directory for output files
        """
        # Initialize components
        self.structurer = DocumentStructurer()
        self.rag = rag_engine or RAGEngine.from_config()
        self.query_processor = QueryProcessor(self.rag)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # Statistics
        self.stats = {
            'start_time': None,
            'end_time': None,
            'total_duration': None,
            'extraction_time': None,
            'analysis_time': None,
            'report_time': None
        }

    def analyze_edital(
        self,
        pdf_path: str,
        output_basename: Optional[str] = None,
        export_formats: List[str] = ['json', 'csv', 'markdown']
    ) -> ConformityReport:
        """
        Analyze edital PDF end-to-end

        Args:
            pdf_path: Path to edital PDF
            output_basename: Base name for output files (default: PDF filename)
            export_formats: List of export formats ('json', 'csv', 'excel', 'markdown')

        Returns:
            ConformityReport with complete analysis
        """
        import time
        self.stats['start_time'] = time.time()

        print(f"\n{'='*70}")
        print(f"üîç AN√ÅLISE COMPLETA DE EDITAL")
        print(f"{'='*70}")
        print(f"üìÑ Arquivo: {pdf_path}")
        print(f"{'='*70}\n")

        # Stage 1: Extract requirements
        print("üìã ETAPA 1/3: Extra√ß√£o de Requisitos")
        extraction_start = time.time()
        structured_data = self._extract_requirements(pdf_path)
        self.stats['extraction_time'] = time.time() - extraction_start

        requirements = structured_data.get('requirements', [])
        metadata = structured_data.get('metadata', {})

        print(f"‚úÖ Extra√≠dos: {len(requirements)} requisitos")
        print(f"‚è±Ô∏è  Tempo: {self.stats['extraction_time']:.1f}s\n")

        # Stage 2: Analyze conformity
        print("üîç ETAPA 2/3: An√°lise de Conformidade (RAG)")
        analysis_start = time.time()
        analysis_results = self._analyze_conformity(requirements)
        self.stats['analysis_time'] = time.time() - analysis_start

        print(f"‚úÖ Analisados: {len(analysis_results)} requisitos")
        print(f"‚è±Ô∏è  Tempo: {self.stats['analysis_time']:.1f}s\n")

        # Stage 3: Generate report
        print("üìä ETAPA 3/3: Gera√ß√£o de Relat√≥rio")
        report_start = time.time()
        report = self._generate_report(metadata, requirements, analysis_results)
        self.stats['report_time'] = time.time() - report_start

        self.stats['end_time'] = time.time()
        self.stats['total_duration'] = self.stats['end_time'] - self.stats['start_time']

        print(f"‚úÖ Relat√≥rio gerado")
        print(f"‚è±Ô∏è  Tempo: {self.stats['report_time']:.1f}s\n")

        # Export
        if output_basename is None:
            output_basename = Path(pdf_path).stem

        self._export(report, output_basename, export_formats)

        # Print summary
        self._print_summary(report)

        return report

    def _extract_requirements(self, pdf_path: str) -> Dict[str, Any]:
        """Extract requirements using Document Structurer"""
        # Use Document Structurer to extract
        result = self.structurer.structure_document(pdf_path)
        return result

    def _analyze_conformity(self, requirements: List[Dict]) -> List[Any]:
        """Analyze conformity using Query Processor"""
        # Batch analyze all requirements
        return self.query_processor.analyze_batch(
            requirements,
            show_progress=True
        )

    def _generate_report(
        self,
        metadata: Dict,
        requirements: List[Dict],
        analysis_results: List[Any]
    ) -> 'ConformityReport':
        """Generate consolidated report"""
        return ConformityReport(
            edital_metadata=metadata,
            requirements=requirements,
            analysis_results=analysis_results,
            timestamp=datetime.now().isoformat(),
            pipeline_stats=self.stats
        )

    def _export(
        self,
        report: 'ConformityReport',
        basename: str,
        formats: List[str]
    ):
        """Export report in multiple formats"""
        exporter = ReportExporter(report, self.output_dir)

        print(f"üíæ EXPORTANDO RESULTADOS")
        print(f"{'='*70}")

        for fmt in formats:
            filepath = exporter.export(basename, fmt)
            print(f"  ‚úÖ {fmt.upper()}: {filepath}")

        print(f"{'='*70}\n")

    def _print_summary(self, report: 'ConformityReport'):
        """Print analysis summary"""
        summary = report.get_summary()

        print(f"{'='*70}")
        print(f"üìä RESUMO DA AN√ÅLISE")
        print(f"{'='*70}")
        print(f"üìã Total de Requisitos: {summary['total_requirements']}")
        print(f"‚úÖ Conformes: {summary['conforme']} ({summary['conforme_pct']:.1f}%)")
        print(f"‚ùå N√£o Conformes: {summary['nao_conforme']} ({summary['nao_conforme_pct']:.1f}%)")
        print(f"‚ö†Ô∏è  Revis√£o Necess√°ria: {summary['revisao']} ({summary['revisao_pct']:.1f}%)")
        print(f"{'='*70}")
        print(f"‚è±Ô∏è  Tempo Total: {self.stats['total_duration']:.1f}s")
        print(f"{'='*70}\n")
```

### 2. ConformityReport (agents/technical_analyst/report.py)

```python
from dataclasses import dataclass, field
from typing import Dict, List, Any
from datetime import datetime
import json


@dataclass
class ConformityReport:
    """Consolidated conformity report"""

    edital_metadata: Dict[str, Any]
    requirements: List[Dict[str, Any]]
    analysis_results: List[Any]  # List[ConformityAnalysis]
    timestamp: str
    pipeline_stats: Dict[str, Any] = field(default_factory=dict)

    def get_summary(self) -> Dict[str, Any]:
        """Get high-level summary statistics"""
        total = len(self.analysis_results)
        conforme = sum(1 for r in self.analysis_results if r.conformity.value == 'CONFORME')
        nao_conforme = sum(1 for r in self.analysis_results if r.conformity.value == 'NAO_CONFORME')
        revisao = sum(1 for r in self.analysis_results if r.conformity.value == 'REVISAO')

        return {
            'total_requirements': total,
            'conforme': conforme,
            'nao_conforme': nao_conforme,
            'revisao': revisao,
            'conforme_pct': (conforme / total * 100) if total > 0 else 0,
            'nao_conforme_pct': (nao_conforme / total * 100) if total > 0 else 0,
            'revisao_pct': (revisao / total * 100) if total > 0 else 0
        }

    def to_dict(self) -> Dict[str, Any]:
        """Convert report to dictionary"""
        return {
            'edital_metadata': self.edital_metadata,
            'summary': self.get_summary(),
            'requirements': self.requirements,
            'analysis_results': [r.to_dict() for r in self.analysis_results],
            'timestamp': self.timestamp,
            'pipeline_stats': self.pipeline_stats
        }

    def to_json(self, indent=2) -> str:
        """Convert to JSON string"""
        return json.dumps(self.to_dict(), indent=indent, ensure_ascii=False)
```

### 3. ReportExporter (agents/technical_analyst/report.py)

```python
import csv
from pathlib import Path
from typing import List, Dict, Any


class ReportExporter:
    """Export conformity reports in multiple formats"""

    def __init__(self, report: ConformityReport, output_dir: Path):
        self.report = report
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def export(self, basename: str, format: str) -> Path:
        """
        Export report in specified format

        Args:
            basename: Base filename (without extension)
            format: Export format ('json', 'csv', 'excel', 'markdown')

        Returns:
            Path to exported file
        """
        if format == 'json':
            return self.to_json(basename)
        elif format == 'csv':
            return self.to_csv(basename)
        elif format == 'excel':
            return self.to_excel(basename)
        elif format == 'markdown':
            return self.to_markdown(basename)
        else:
            raise ValueError(f"Unsupported format: {format}")

    def to_json(self, basename: str) -> Path:
        """Export as JSON"""
        filepath = self.output_dir / f"{basename}_analysis.json"
        filepath.write_text(self.report.to_json(), encoding='utf-8')
        return filepath

    def to_csv(self, basename: str) -> Path:
        """Export as CSV (requirements + analysis)"""
        filepath = self.output_dir / f"{basename}_analysis.csv"

        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            fieldnames = [
                'id', 'descricao', 'tipo', 'categoria', 'prioridade',
                'veredicto', 'confianca', 'evidencias_count', 'reasoning'
            ]
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()

            for req, analysis in zip(self.report.requirements, self.report.analysis_results):
                writer.writerow({
                    'id': req.get('id', ''),
                    'descricao': req.get('descricao', ''),
                    'tipo': req.get('tipo', ''),
                    'categoria': req.get('categoria', ''),
                    'prioridade': req.get('prioridade', ''),
                    'veredicto': analysis.conformity.value,
                    'confianca': f"{analysis.confidence:.2f}",
                    'evidencias_count': len(analysis.evidence),
                    'reasoning': analysis.reasoning
                })

        return filepath

    def to_markdown(self, basename: str) -> Path:
        """Export as Markdown report"""
        filepath = self.output_dir / f"{basename}_report.md"

        summary = self.report.get_summary()

        md = f"""# Relat√≥rio de An√°lise de Conformidade

**Edital:** {self.report.edital_metadata.get('numero_edital', 'N/A')}
**√ìrg√£o:** {self.report.edital_metadata.get('orgao', 'N/A')}
**Data da An√°lise:** {self.report.timestamp}

---

## üìä Resumo Executivo

| M√©trica | Valor |
|---------|-------|
| Total de Requisitos | {summary['total_requirements']} |
| ‚úÖ Conformes | {summary['conforme']} ({summary['conforme_pct']:.1f}%) |
| ‚ùå N√£o Conformes | {summary['nao_conforme']} ({summary['nao_conforme_pct']:.1f}%) |
| ‚ö†Ô∏è Revis√£o Necess√°ria | {summary['revisao']} ({summary['revisao_pct']:.1f}%) |

---

## üìã An√°lise Detalhada

"""

        for req, analysis in zip(self.report.requirements, self.report.analysis_results):
            verdict_emoji = {
                'CONFORME': '‚úÖ',
                'NAO_CONFORME': '‚ùå',
                'REVISAO': '‚ö†Ô∏è'
            }.get(analysis.conformity.value, '‚ùì')

            md += f"""
### {verdict_emoji} {req.get('id', 'N/A')}: {req.get('descricao', 'N/A')}

- **Tipo:** {req.get('tipo', 'N/A')}
- **Categoria:** {req.get('categoria', 'N/A')}
- **Veredicto:** {analysis.conformity.value}
- **Confian√ßa:** {analysis.confidence:.0%}
- **Evid√™ncias:** {len(analysis.evidence)} fonte(s)

**Racioc√≠nio:** {analysis.reasoning}

**Recomenda√ß√µes:**
{chr(10).join(f"- {rec}" for rec in analysis.recommendations)}

---

"""

        filepath.write_text(md, encoding='utf-8')
        return filepath

    def to_excel(self, basename: str) -> Path:
        """Export as Excel (requires openpyxl)"""
        try:
            import openpyxl
            from openpyxl.styles import Font, PatternFill
        except ImportError:
            raise ImportError("openpyxl required for Excel export. Install with: pip install openpyxl")

        filepath = self.output_dir / f"{basename}_analysis.xlsx"
        wb = openpyxl.Workbook()

        # Sheet 1: Summary
        ws_summary = wb.active
        ws_summary.title = "Resumo"
        summary = self.report.get_summary()

        ws_summary['A1'] = "M√©trica"
        ws_summary['B1'] = "Valor"
        ws_summary['A1'].font = Font(bold=True)
        ws_summary['B1'].font = Font(bold=True)

        ws_summary['A2'] = "Total de Requisitos"
        ws_summary['B2'] = summary['total_requirements']
        ws_summary['A3'] = "Conformes"
        ws_summary['B3'] = summary['conforme']
        ws_summary['A4'] = "N√£o Conformes"
        ws_summary['B4'] = summary['nao_conforme']
        ws_summary['A5'] = "Revis√£o Necess√°ria"
        ws_summary['B5'] = summary['revisao']

        # Sheet 2: Detailed Analysis
        ws_detail = wb.create_sheet("An√°lise Detalhada")
        headers = ['ID', 'Descri√ß√£o', 'Tipo', 'Categoria', 'Veredicto', 'Confian√ßa', 'Evid√™ncias', 'Racioc√≠nio']
        ws_detail.append(headers)

        for cell in ws_detail[1]:
            cell.font = Font(bold=True)

        for req, analysis in zip(self.report.requirements, self.report.analysis_results):
            ws_detail.append([
                req.get('id', ''),
                req.get('descricao', ''),
                req.get('tipo', ''),
                req.get('categoria', ''),
                analysis.conformity.value,
                analysis.confidence,
                len(analysis.evidence),
                analysis.reasoning
            ])

        wb.save(filepath)
        return filepath
```

---

## üì¶ Comando /analyze-edital

```python
# .claude/commands/analyze-edital.md

You are helping analyze a public procurement edital (PDF) using the BidAnalyzee system.

The analysis pipeline performs:
1. Document Structurer: Extract requirements from PDF
2. Technical Analyst: Analyze conformity against knowledge base using RAG
3. Report Generator: Create consolidated reports

Usage:
```
/analyze-edital <path-to-pdf> [options]
```

Options:
- `--formats csv,json,markdown,excel` - Export formats (default: json,csv,markdown)
- `--output-dir <path>` - Output directory (default: output/analysis)

Example:
```
/analyze-edital editais/edital_001.pdf --formats json,csv,markdown
```

Implementation:
1. Use AnalysisPipeline.analyze_edital() to process the PDF
2. Display progress and summary
3. Report output file locations
```

---

## üß™ Testes

### Integration Test (tests/integration/test_analysis_pipeline.py)

```python
import pytest
from pathlib import Path
from agents.technical_analyst.pipeline import AnalysisPipeline


class TestAnalysisPipeline:
    """Integration tests for analysis pipeline"""

    @pytest.fixture
    def pipeline(self, mock_rag_engine):
        """Create pipeline with mocked RAG"""
        return AnalysisPipeline(
            rag_engine=mock_rag_engine,
            output_dir="output/test"
        )

    def test_full_pipeline_mock_pdf(self, pipeline, sample_pdf):
        """Test complete pipeline with mock PDF"""
        report = pipeline.analyze_edital(
            sample_pdf,
            export_formats=['json', 'csv']
        )

        assert report is not None
        assert len(report.requirements) > 0
        assert len(report.analysis_results) == len(report.requirements)

        summary = report.get_summary()
        assert summary['total_requirements'] > 0
        assert summary['conforme'] + summary['nao_conforme'] + summary['revisao'] == summary['total_requirements']
```

---

## üìä M√©tricas de Sucesso

| M√©trica | Target |
|---------|--------|
| Tempo total (50 reqs) | < 5 minutos |
| Taxa de sucesso | 100% (sem crashes) |
| Cobertura de testes | > 85% |
| Formatos de export | 4 (JSON, CSV, Excel, Markdown) |
| Integra√ß√£o | Document Structurer + Query Processor |

---

## ‚úÖ Definition of Done

- [ ] `AnalysisPipeline` implementado e testado
- [ ] `ConformityReport` e `ReportExporter` funcionais
- [ ] Integra√ß√£o end-to-end funcional
- [ ] 4 formatos de export (JSON, CSV, Excel, Markdown)
- [ ] Comando `/analyze-edital` implementado
- [ ] Testes de integra√ß√£o passando
- [ ] Documenta√ß√£o completa
- [ ] Performance < 5min para edital t√≠pico
- [ ] C√≥digo commitado e pushed

---

**Status:** üöÄ Ready to Start
**Pr√≥ximo Passo:** Implementar AnalysisPipeline
**Data:** 08 de novembro de 2025
