# BidAnalyzee - Environment Variables
# Copy this file to .env and fill in your actual values
# NEVER commit .env to version control!

# ============================================
# RAG CONFIGURATION - SPRINT 5 (LOCAL SETUP)
# ============================================
# Vector Store: faiss (local) | pinecone (cloud - future)
RAG_VECTOR_STORE=faiss

# FAISS Configuration (Local Vector Store)
RAG_FAISS_INDEX_PATH=data/vector_store/faiss

# Embeddings Provider: local (sentence-transformers) | openai (future)
RAG_EMBEDDINGS_PROVIDER=local

# Local Embeddings Model (sentence-transformers)
# Options: all-MiniLM-L6-v2 (384 dim, fast), paraphrase-multilingual-mpnet-base-v2 (768 dim, better quality)
RAG_EMBEDDINGS_MODEL=all-MiniLM-L6-v2
RAG_EMBEDDINGS_DIMENSION=384

# Knowledge Base Configuration
RAG_KNOWLEDGE_BASE_PATH=data/knowledge_base/mock
RAG_CHUNK_SIZE=1000
RAG_CHUNK_OVERLAP=200

# Search Configuration
RAG_TOP_K=5
RAG_SIMILARITY_THRESHOLD=0.7

# ============================================
# PINECONE CONFIGURATION (FUTURE - CLOUD MIGRATION)
# ============================================
# Uncomment and configure when migrating to Pinecone cloud

# Your Pinecone API key (get from: https://app.pinecone.io/)
# PINECONE_API_KEY=your_pinecone_api_key_here

# Your Pinecone environment (e.g., us-west1-gcp, eu-west1-gcp)
# PINECONE_ENVIRONMENT=your_pinecone_environment_here

# Your Pinecone index name
# PINECONE_INDEX_NAME=bidanalyzee-knowledge-base

# Index configuration (for when you create it)
# PINECONE_DIMENSION=1536
# PINECONE_METRIC=cosine

# To migrate to Pinecone: Change RAG_VECTOR_STORE=pinecone and uncomment above

# ============================================
# OPENAI EMBEDDINGS (FUTURE - CLOUD MIGRATION)
# ============================================
# Uncomment when migrating to OpenAI embeddings for better quality

# OpenAI API key
# OPENAI_API_KEY=sk-...

# OpenAI embeddings model
# OPENAI_EMBEDDINGS_MODEL=text-embedding-3-small
# OPENAI_EMBEDDINGS_DIMENSION=1536

# To migrate to OpenAI: Change RAG_EMBEDDINGS_PROVIDER=openai and uncomment above

# ============================================
# N8N CONFIGURATION (FUTURE - AUTOMATED INGESTION)
# ============================================
# Uncomment when setting up n8n workflow for automated documentation ingestion

# URL of your n8n instance (self-hosted or cloud)
# N8N_BASE_URL=https://hacktheplanet.net.br

# n8n webhook URL for ingestion pipeline
# N8N_INGESTION_WEBHOOK_URL=https://hacktheplanet.net.br/webhook/ingest-docs

# n8n API key (if using authenticated endpoints)
# N8N_API_KEY=your_n8n_api_key_here

# ============================================
# SYSTEM CONFIGURATION
# ============================================
# Confidence threshold for conformity analysis (NFR2: > 85%)
CONFIDENCE_THRESHOLD=0.85

# Number of results to retrieve from Pinecone (before re-ranking)
TOP_K_RESULTS=20

# Number of results to keep after re-ranking
RERANK_TOP_N=5

# Maximum number of LOOP iterations before forcing HALT (SHIELD)
MAX_LOOP_ITERATIONS=3

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# ============================================
# DATA SOURCE CONFIGURATION (for n8n ingestion)
# ============================================
# Base URL of the technical documentation portal
# STATUS: Public access (no authentication required)
# NOTE: No API available - web scraping will be used
TECHDOCS_BASE_URL=https://techdocs.genetec.com

# Scraping interval (in days) - default: 120 days (4 months)
SCRAPING_INTERVAL_DAYS=120

# Scraping configuration
# Since there's no API, we'll implement rate limiting on our side
SCRAPING_DELAY_SECONDS=2
SCRAPING_MAX_CONCURRENT_REQUESTS=3

# Google Sheets ID for URL tracking (MVP only)
GOOGLE_SHEETS_ID=your_google_sheets_id_here

# Google Sheets API credentials path (JSON file)
GOOGLE_CREDENTIALS_PATH=./credentials/google_credentials.json

# ============================================
# OPTIONAL: CLAUDE API (if needed for embeddings or custom models)
# ============================================
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ============================================
# PROJECT PATHS (usually no need to change)
# ============================================
# Root directory for data storage
DATA_ROOT=./data

# Directory for analyses
ANALYSES_DIR=./data/analyses

# Directory for state files
STATE_DIR=./data/state

# Directory for templates
TEMPLATES_DIR=./data/templates

# ============================================
# DEVELOPMENT / DEBUG
# ============================================
# Enable detailed logging of SHIELD phases (true/false)
DEBUG_SHIELD=false

# Enable token usage logging (true/false)
LOG_TOKEN_USAGE=true

# Dry run mode (simulates operations without executing - for testing)
DRY_RUN=false
