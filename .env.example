# BidAnalyzee - Environment Variables
# Copy this file to .env and fill in your actual values
# NEVER commit .env to version control!

# ============================================
# PINECONE CONFIGURATION
# ============================================
# STATUS: Account needs to be created (see docs/PINECONE_SETUP.md)
# Follow the setup guide to create your free account and get these values

# Your Pinecone API key (get from: https://app.pinecone.io/)
PINECONE_API_KEY=your_pinecone_api_key_here

# Your Pinecone environment (e.g., us-west1-gcp, eu-west1-gcp)
PINECONE_ENVIRONMENT=your_pinecone_environment_here

# Your Pinecone index name
PINECONE_INDEX_NAME=bidanalyzee-knowledge-base

# Index configuration (for when you create it)
PINECONE_DIMENSION=1536
PINECONE_METRIC=cosine

# ============================================
# N8N CONFIGURATION
# ============================================
# URL of your n8n instance (self-hosted or cloud)
# Your instance: Self-hosted (Docker) at https://hacktheplanet.net.br/
N8N_BASE_URL=https://hacktheplanet.net.br

# n8n webhook URL for the query service (from HistÃ³ria 3.2)
# Update the path after creating the webhook workflow
N8N_QUERY_SERVICE_URL=https://hacktheplanet.net.br/webhook/query

# n8n API key (if using authenticated endpoints)
# Generate this from your n8n instance: Settings > API
N8N_API_KEY=your_n8n_api_key_here

# ============================================
# EMBEDDING MODEL CONFIGURATION
# ============================================
# Embedding model to use (default: llama-text-embed-v2)
EMBEDDING_MODEL=llama-text-embed-v2

# Embedding API endpoint (if using external service)
EMBEDDING_API_URL=https://api.example.com/embeddings

# Embedding API key (if required)
EMBEDDING_API_KEY=your_embedding_api_key_here

# ============================================
# SYSTEM CONFIGURATION
# ============================================
# Confidence threshold for conformity analysis (NFR2: > 85%)
CONFIDENCE_THRESHOLD=0.85

# Number of results to retrieve from Pinecone (before re-ranking)
TOP_K_RESULTS=20

# Number of results to keep after re-ranking
RERANK_TOP_N=5

# Maximum number of LOOP iterations before forcing HALT (SHIELD)
MAX_LOOP_ITERATIONS=3

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# ============================================
# DATA SOURCE CONFIGURATION (for n8n ingestion)
# ============================================
# Base URL of the technical documentation portal
# STATUS: Public access (no authentication required)
# NOTE: No API available - web scraping will be used
TECHDOCS_BASE_URL=https://techdocs.genetec.com

# Scraping interval (in days) - default: 120 days (4 months)
SCRAPING_INTERVAL_DAYS=120

# Scraping configuration
# Since there's no API, we'll implement rate limiting on our side
SCRAPING_DELAY_SECONDS=2
SCRAPING_MAX_CONCURRENT_REQUESTS=3

# Google Sheets ID for URL tracking (MVP only)
GOOGLE_SHEETS_ID=your_google_sheets_id_here

# Google Sheets API credentials path (JSON file)
GOOGLE_CREDENTIALS_PATH=./credentials/google_credentials.json

# ============================================
# OPTIONAL: CLAUDE API (if needed for embeddings or custom models)
# ============================================
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ============================================
# PROJECT PATHS (usually no need to change)
# ============================================
# Root directory for data storage
DATA_ROOT=./data

# Directory for analyses
ANALYSES_DIR=./data/analyses

# Directory for state files
STATE_DIR=./data/state

# Directory for templates
TEMPLATES_DIR=./data/templates

# ============================================
# DEVELOPMENT / DEBUG
# ============================================
# Enable detailed logging of SHIELD phases (true/false)
DEBUG_SHIELD=false

# Enable token usage logging (true/false)
LOG_TOKEN_USAGE=true

# Dry run mode (simulates operations without executing - for testing)
DRY_RUN=false
