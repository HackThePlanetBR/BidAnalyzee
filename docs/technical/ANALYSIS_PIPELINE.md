# Analysis Pipeline - End-to-End Integration

**Status:** ‚úÖ COMPLETO (Sprint 5.3)
**Vers√£o:** 0.3.0
**Data:** 08 de novembro de 2025

---

## üìã Vis√£o Geral

O **Analysis Pipeline** integra o Document Structurer com o Technical Analyst Query Processor para fornecer an√°lise completa de conformidade end-to-end.

### Pipeline Completo

```
PDF Edital ‚Üí Document Structurer ‚Üí Requirements CSV
                                          ‚Üì
                                    Query Processor
                                          ‚Üì
                                    RAG Analysis
                                          ‚Üì
                                 Conformity Report
                                          ‚Üì
                            Export (JSON/CSV/Excel/Markdown)
```

---

## üöÄ Uso R√°pido

### Comando CLI

```bash
# Passo 1: Estruturar edital (extrai requisitos)
/structure-edital data/uploads/edital_001.pdf

# Passo 2: Analisar conformidade
/analyze-edital data/deliveries/analysis_edital_001_20250108/outputs/requirements_structured.csv
```

### API Python

```python
from agents.technical_analyst import AnalysisPipeline

# Criar pipeline
pipeline = AnalysisPipeline(output_dir="output/analysis")

# Analisar requirements CSV
report = pipeline.analyze_from_csv(
    "requirements.csv",
    export_formats=['json', 'csv', 'markdown', 'excel']
)

# Ver resumo
summary = report.get_summary()
print(f"Taxa de Conformidade: {summary['overall_compliance_rate']:.1f}%")
print(f"Conformes: {summary['conforme']}")
print(f"Revis√£o Necess√°ria: {summary['revisao']}")
```

---

## üì¶ Componentes

### 1. AnalysisPipeline

Orquestra todo o fluxo end-to-end:

```python
from agents.technical_analyst.pipeline import AnalysisPipeline

pipeline = AnalysisPipeline(
    rag_engine=None,  # Usa default (FAISS local)
    output_dir="output/analysis"
)
```

**M√©todos principais:**
- `analyze_from_csv()` - Analisa a partir de CSV do Document Structurer
- `analyze_requirements()` - Analisa lista de requisitos diretamente
- `get_stats()` - Retorna estat√≠sticas de performance

### 2. ConformityReport

Estrutura consolidada do relat√≥rio de an√°lise:

```python
from agents.technical_analyst.report import ConformityReport

# Acessar dados do relat√≥rio
summary = report.get_summary()
critical_issues = report.get_critical_issues()
review_needed = report.get_review_needed()
recommendations = report.get_recommendations()

# Exportar
json_data = report.to_json()
dict_data = report.to_dict()
```

### 3. ReportExporter

Exporta relat√≥rios em m√∫ltiplos formatos:

```python
from agents.technical_analyst.report import ReportExporter

exporter = ReportExporter(report, output_dir="output")

# Exportar em formato espec√≠fico
json_file = exporter.to_json("analysis")
csv_file = exporter.to_csv("analysis")
excel_file = exporter.to_excel("analysis")  # Requer openpyxl
md_file = exporter.to_markdown("analysis")
```

---

## üìä Formatos de Export

### JSON (Completo)

Dados estruturados completos incluindo:
- Metadados do edital
- Requisitos extra√≠dos
- Resultados de an√°lise por requisito
- Evid√™ncias e fontes
- Estat√≠sticas e recomenda√ß√µes

```json
{
  "edital_metadata": {...},
  "summary": {
    "total_requirements": 50,
    "conforme": 35,
    "nao_conforme": 2,
    "revisao": 13,
    "overall_compliance_rate": 70.0
  },
  "requirements": [...],
  "analysis_results": [...],
  "critical_issues": [...],
  "review_needed": [...],
  "consolidated_recommendations": [...],
  "timestamp": "2025-11-08T12:00:00"
}
```

### CSV (Tabular)

Formato planilha com uma linha por requisito:

| id | descricao | tipo | categoria | veredicto | confianca | evidencias_count | fontes | reasoning |
|----|-----------|------|-----------|-----------|-----------|------------------|--------|-----------|
| REQ-001 | C√¢meras IP 4MP | T√©cnico | Hardware | CONFORME | 0.92 | 3 | requisitos_tecnicos.md | Requisito em conformidade... |

### Excel (Multi-sheet)

Planilha Excel com 2 abas:
- **Resumo**: Estat√≠sticas gerais
- **An√°lise Detalhada**: Todos os requisitos com an√°lise

### Markdown (Human-readable)

Relat√≥rio formatado para leitura:
- Resumo executivo
- Quest√µes cr√≠ticas destacadas
- Requisitos necessitando revis√£o
- An√°lise detalhada por requisito

---

## üéØ Veredictos de Conformidade

| Veredicto | Crit√©rio | Significado |
|-----------|----------|-------------|
| **CONFORME** | Confian√ßa ‚â• 0.85 E Evid√™ncias ‚â• 2 | Requisito atende documenta√ß√£o |
| **NAO_CONFORME** | Contradiz explicitamente documenta√ß√£o | Requisito n√£o atende |
| **REVISAO** | Confian√ßa < 0.85 OU Evid√™ncias < 2 | Requer revis√£o manual |

**Score de Confian√ßa:**
- Weighted: 70% relev√¢ncia m√©dia + 30% relev√¢ncia m√°xima
- Range: 0.0 (sem match) a 1.0 (match perfeito)

---

## ‚è±Ô∏è Performance

### M√©tricas T√≠picas

| Cen√°rio | Requisitos | Tempo Esperado |
|---------|------------|----------------|
| Pequeno | 10-20 | < 30s |
| M√©dio | 30-50 | < 2 min |
| Grande | 100+ | < 5 min |

### Rastreamento

O pipeline rastreia automaticamente:
- Tempo de carregamento do CSV
- Tempo de an√°lise RAG
- Tempo de gera√ß√£o de relat√≥rio
- Tempo total

```python
stats = pipeline.get_stats()
print(f"Tempo total: {stats['total_duration']:.1f}s")
print(f"  Carregamento: {stats['extraction_time']:.1f}s")
print(f"  An√°lise: {stats['analysis_time']:.1f}s")
print(f"  Relat√≥rio: {stats['report_time']:.1f}s")
```

---

## üìñ Exemplos

### Exemplo 1: An√°lise B√°sica

```python
from agents.technical_analyst import AnalysisPipeline

pipeline = AnalysisPipeline()

report = pipeline.analyze_from_csv(
    "data/deliveries/analysis_edital_001/outputs/requirements.csv"
)

print(f"Total: {len(report.requirements)} requisitos")
print(f"Conformes: {report.get_summary()['conforme']}")
```

### Exemplo 2: Requisitos Diretos (Sem CSV)

```python
requirements = [
    {'id': 'REQ-001', 'descricao': 'C√¢meras 4MP', 'tipo': 'T√©cnico'},
    {'id': 'REQ-002', 'descricao': 'Armazenamento 30 dias', 'tipo': 'T√©cnico'}
]

report = pipeline.analyze_requirements(
    requirements=requirements,
    metadata={'numero_edital': '001/2024'},
    export_formats=['json', 'markdown']
)
```

### Exemplo 3: Quest√µes Cr√≠ticas

```python
# Identificar requisitos n√£o conformes
critical = report.get_critical_issues()

for issue in critical:
    req = issue['requirement']
    analysis = issue['analysis']
    print(f"‚ùå {req['id']}: {req['descricao']}")
    print(f"   Confian√ßa: {analysis['confidence']:.0%}")
    print(f"   Raz√£o: {analysis['reasoning']}\n")
```

### Exemplo 4: Exporta√ß√£o Customizada

```python
from agents.technical_analyst.report import ReportExporter

exporter = ReportExporter(report, output_dir="reports/custom")

# Exportar apenas formatos espec√≠ficos
exporter.to_json("edital_001")
exporter.to_markdown("edital_001")

# Excel requer openpyxl
try:
    exporter.to_excel("edital_001")
except ImportError:
    print("Install openpyxl for Excel export")
```

---

## üîß Configura√ß√£o

### RAG Engine

Por padr√£o usa FAISS local. Para customizar:

```python
from agents.technical_analyst import RAGEngine, AnalysisPipeline

# Criar RAG engine customizado
rag = RAGEngine.from_config()
rag.ingest_knowledge_base("data/knowledge_base/custom")

# Usar no pipeline
pipeline = AnalysisPipeline(rag_engine=rag)
```

### Diret√≥rio de Output

```python
pipeline = AnalysisPipeline(output_dir="custom/output/path")
```

---

## üö® Tratamento de Erros

### CSV n√£o encontrado

```python
try:
    report = pipeline.analyze_from_csv("nonexistent.csv")
except FileNotFoundError as e:
    print(f"‚ùå Arquivo n√£o encontrado: {e}")
```

### CSV vazio

```python
report = pipeline.analyze_from_csv("empty.csv")
summary = report.get_summary()

if summary['total_requirements'] == 0:
    print("‚ö†Ô∏è Nenhum requisito encontrado no CSV")
```

### Falha em Export

```python
try:
    pipeline.analyze_from_csv("requirements.csv", export_formats=['excel'])
except ImportError:
    print("‚ö†Ô∏è openpyxl n√£o instalado. Use: pip install openpyxl")
```

---

## üìö Integra√ß√£o com Document Structurer

### Workflow Completo

```bash
# 1. Estruturar edital
/structure-edital editais/edital_pmsp_001.pdf

# Output: data/deliveries/analysis_edital_pmsp_001_20250108/outputs/requirements_structured.csv

# 2. Analisar conformidade
/analyze-edital data/deliveries/analysis_edital_pmsp_001_20250108/outputs/requirements_structured.csv --formats json,csv,markdown,excel

# Outputs em output/analysis/:
# - edital_pmsp_001_analysis.json
# - edital_pmsp_001_analysis.csv
# - edital_pmsp_001_analysis.xlsx
# - edital_pmsp_001_report.md
```

### Formatos CSV Suportados

O pipeline aceita CSVs do Document Structurer com os seguintes campos:

**Obrigat√≥rios:**
- `ID` ou `id`: Identificador do requisito
- `Descri√ß√£o` ou `descricao`: Texto do requisito

**Opcionais:**
- `Item`: N√∫mero do item no edital
- `Categoria` ou `categoria`: Hardware/Software/etc
- `Prioridade` ou `prioridade`: Alta/M√©dia/Baixa
- `P√°gina` ou `pagina`: P√°gina de origem
- `Confian√ßa` ou `confianca`: Score de confian√ßa

---

## ‚úÖ Sprint 5.3 - Definition of Done

- [x] AnalysisPipeline implementado
- [x] ConformityReport e ReportExporter funcionais
- [x] Integra√ß√£o com Document Structurer CSV
- [x] 4 formatos de export (JSON, CSV, Excel, Markdown)
- [x] Comando `/analyze-edital` implementado
- [x] Testes de integra√ß√£o criados
- [x] Documenta√ß√£o completa
- [x] Performance tracking
- [x] Error handling robusto

---

## üéØ Pr√≥ximos Passos

**Sprint 5.4 (Futuro):**
- Dashboard web para visualiza√ß√£o de resultados
- Integra√ß√£o com banco de dados para hist√≥rico
- APIs REST para an√°lise remota
- An√°lise comparativa entre m√∫ltiplos editais

---

**√öltima atualiza√ß√£o:** 08 de novembro de 2025
**Vers√£o:** 0.3.0
**Status:** ‚úÖ Production Ready
